{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from torch import nn\n",
    "from timm.data.loader import create_loader\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "\n",
    "from imp import reload\n",
    "from collections import defaultdict\n",
    "from types import SimpleNamespace\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from timm.optim import create_optimizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import (\n",
    "    resolve_data_config,\n",
    ")\n",
    "from timm.models import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aditya/chipbrain/cleanlab/celaba\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"img_align_celeba/all.csv\")\n",
    "\n",
    "set_lab = {}\n",
    "for i,row in df.iterrows():\n",
    "    q = str(row.tolist()[1:])\n",
    "    if q not in set_lab:\n",
    "        set_lab[(str(q))]=len(set_lab)\n",
    "\n",
    "def get_lab(row):\n",
    "    q = str(row.tolist()[1:])\n",
    "    return set_lab[q]\n",
    "\n",
    "df['unique_label'] = df.apply(get_lab,axis=1)\n",
    "\n",
    "\n",
    "cnt = Counter(df['unique_label'])\n",
    "\n",
    "def drop(val):\n",
    "    if cnt[val]>10:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "is_drop = df['unique_label'].apply(lambda x:drop(x))\n",
    "\n",
    "\n",
    "\n",
    "df[is_drop].to_csv(\"img_align_celeba/all2.csv\",index=False)\n",
    "\n",
    "df = pd.read_csv(\"img_align_celeba/all2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiLabelModel(nn.Module):\n",
    "    def __init__(self, model, n_classes,class_weights = None):\n",
    "        super().__init__()\n",
    "        self.base_model = model\n",
    "        self.num_classes = n_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_loss(self,loss_fn, output, target):\n",
    "        \n",
    "        return loss_fn(output,target)\n",
    "\n",
    "    def validate(self,loader):\n",
    "        self.eval();\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            m = nn.Sigmoid()\n",
    "            ops = []\n",
    "            labels = []\n",
    "            preds = []\n",
    "            for batch_idx, (input, target) in enumerate(loader):\n",
    "                input = input.cuda()\n",
    "                labels.append(target.detach().cpu())\n",
    "                target = target.float().cuda()\n",
    "                output = m(self(input))\n",
    "                loss = self.get_loss(loss_fn, output, target)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                pred_model = (output>0.5).detach().cpu()\n",
    "                preds.append(pred_model)\n",
    "\n",
    "            num_of_batches_per_epoch = len(loader)\n",
    "            avg_loss = total_loss / num_of_batches_per_epoch\n",
    "            print(\"VALIDATION DATA STATS\")\n",
    "\n",
    "            print(\"AVERAGE LOSS:\",avg_loss)\n",
    "            preds = torch.cat(preds).int()\n",
    "            labels = torch.cat(labels).int()\n",
    "            acc_score = accuracy_score(labels,preds)\n",
    "            print(\"MULTILABEL accuracy score:\",acc_score)\n",
    "            per_class = []\n",
    "            for i in range(len(preds.T)):\n",
    "                per_class.append(accuracy_score(labels.T[i],preds.T[i]))\n",
    "            print(dataset_train.label_names)\n",
    "            print(per_class)\n",
    "            print('\\n\\n')\n",
    "        return avg_loss\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict_proba(self,loader):\n",
    "        self.eval();\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            m = nn.Sigmoid()\n",
    "            ops = []\n",
    "            labels = []\n",
    "            preds = []\n",
    "            for batch_idx, (input, target) in enumerate(loader):\n",
    "                input = input.cuda()\n",
    "                output = m(self(input))\n",
    "                pred_model = output.detach().cpu()\n",
    "                preds.append(pred_model)\n",
    "\n",
    "            num_of_batches_per_epoch = len(loader)\n",
    "            avg_loss = total_loss / num_of_batches_per_epoch\n",
    "            preds = torch.cat(preds)\n",
    "        return preds\n",
    "    \n",
    "    def fit(self,loader_train,load_val, num_epochs = 10 ):\n",
    "        if os.path.exists(\"weights_model\"):\n",
    "            print(\"removing weights directory\")\n",
    "            os.system('rm -rf weights_model')\n",
    "        os.mkdir(\"weights_model\")\n",
    "        args = SimpleNamespace()\n",
    "        args.weight_decay = 0\n",
    "        args.lr = 1e-4\n",
    "        args.opt = 'adam' \n",
    "        args.momentum = 0.9\n",
    "        args.sched = \"step\"\n",
    "            \n",
    "        optimizer = create_optimizer(args, self)\n",
    "        saver = CheckpointSaver(\n",
    "            model=self,\n",
    "            optimizer=optimizer,\n",
    "            checkpoint_dir=\"weights_model\"\n",
    "            )\n",
    "        errs = []\n",
    "        num_of_data_train = len(loader_train.dataset.data)\n",
    "        for epoch in range(0,num_epochs):\n",
    "            loss_train = train_one_epoch(\n",
    "            num_of_data_train,\n",
    "            epoch,\n",
    "            self,\n",
    "            loader_train,\n",
    "            optimizer,\n",
    "            loss_fn,\n",
    "        )\n",
    "            loss_val = self.validate(loader_val)\n",
    "            errs.append([loss_train,loss_val])\n",
    "            saver.save_checkpoint(epoch,metric=loss_val)\n",
    "    \n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "        num_of_data_train,\n",
    "        epoch,\n",
    "        model,\n",
    "        loader,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        lr_scheduler=None,\n",
    "        saver=None,\n",
    "        output_dir=\"\",\n",
    "        ):\n",
    "        sta = time.time()\n",
    "        second_order = hasattr(optimizer, \"is_second_order\") and optimizer.is_second_order\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        m = nn.Sigmoid()\n",
    "        ops = []\n",
    "        labels = []\n",
    "        preds = []\n",
    "        ct=0\n",
    "        for batch_idx, (input, target) in enumerate(loader):\n",
    "                input = input.cuda()\n",
    "                ct+=1\n",
    "                labels.append(target.detach().cpu())\n",
    "                target = target.float().cuda()\n",
    "                output = m(model(input))\n",
    "                loss = model.get_loss(loss_fn, output, target)\n",
    "                total_loss += loss.item()\n",
    "                pred_model = (output>0.5).detach().cpu()\n",
    "                preds.append(pred_model)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(create_graph=second_order)\n",
    "                optimizer.step()\n",
    "                if ct%80==0:\n",
    "                    print(\"LOSS:\",loss.item())\n",
    "        num_of_batches_per_epoch = len(loader)\n",
    "        avg_loss = total_loss / num_of_batches_per_epoch\n",
    "        print(\"TRAINING DATA STATS\")\n",
    "        print(\"AVERAGE LOSS:\",avg_loss)\n",
    "        preds = torch.cat(preds).int()\n",
    "        labels = torch.cat(labels).int()\n",
    "        acc_score = accuracy_score(labels,preds)\n",
    "        print(\"MULTILABEL accuracy score:\",acc_score)\n",
    "        per_class = []\n",
    "        for i in range(len(preds.T)):\n",
    "            per_class.append(accuracy_score(labels.T[i],preds.T[i]))\n",
    "        print(dataset_train.label_names)\n",
    "        print(per_class)\n",
    "        print('\\n\\n')\n",
    "        sto = time.time()\n",
    "        print(\"training time\",sto-sta)\n",
    "        return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetMultiLabel(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            annotation_path=None,\n",
    "            df = None,\n",
    "            transform=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.label_names = []\n",
    "        if annotation_path is None:\n",
    "            assert df is not None\n",
    "        else:\n",
    "            df = pd.read_csv(annotation_path)\n",
    "        \n",
    "        cols = df.columns\n",
    "        self.label_names = list(cols[1:-1])\n",
    "        for i,row in df.iterrows():\n",
    "            lb = []\n",
    "            for j in cols:\n",
    "                if j=='unique_label':\n",
    "                    continue\n",
    "                if j=='image_path':\n",
    "                    self.data.append(row[j])\n",
    "                else:\n",
    "                    lb.append(float(row[j]))\n",
    "            self.labels.append(lb)\n",
    "                \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        labels = self.labels[idx]\n",
    "\n",
    "        return img, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetMultiLabel(df = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "    'efficientnet_b0',\n",
    "    num_classes=len(dataset.labels[0]),\n",
    ")\n",
    "data_config = resolve_data_config(\n",
    "       args = {}, model=model\n",
    "    )\n",
    "\n",
    "model = MultiLabelModel(\n",
    "        model,\n",
    "        n_classes=len(dataset.labels[0]),\n",
    "    ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=num_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "#         print(f'Reset trainable parameters of layer = {layer}')\n",
    "        layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(pred_probs,dataset):\n",
    "    ls = dataset_val.label_names\n",
    "    cl = defaultdict(list)\n",
    "    cl['image_loc'] = dataset.data\n",
    "    for i in range(0,len(ls)):\n",
    "        cl[ls[i]] = pred_val.T[i].tolist()\n",
    "    return pd.DataFrame.from_dict(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_val = model.predict_proba(loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.utils import CheckpointSaver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.43037253618240356\n",
      "LOSS: 0.39355307817459106\n",
      "LOSS: 0.395964115858078\n",
      "LOSS: 0.3461613357067108\n",
      "LOSS: 0.36866986751556396\n",
      "LOSS: 0.4578284025192261\n",
      "LOSS: 0.42840054631233215\n",
      "LOSS: 0.3487946689128876\n",
      "LOSS: 0.4757138788700104\n",
      "LOSS: 0.3831671476364136\n",
      "LOSS: 0.38085877895355225\n",
      "LOSS: 0.3592175245285034\n",
      "LOSS: 0.34022796154022217\n",
      "LOSS: 0.3761342465877533\n",
      "LOSS: 0.32846173644065857\n",
      "LOSS: 0.42721328139305115\n",
      "LOSS: 0.4486467242240906\n",
      "LOSS: 0.3618222773075104\n",
      "LOSS: 0.38367760181427\n",
      "LOSS: 0.35117629170417786\n",
      "LOSS: 0.3657556474208832\n",
      "LOSS: 0.3876534402370453\n",
      "LOSS: 0.38139352202415466\n",
      "LOSS: 0.3599325716495514\n",
      "LOSS: 0.3820578157901764\n",
      "LOSS: 0.3913615942001343\n",
      "LOSS: 0.3237290382385254\n",
      "TRAINING DATA STATS\n",
      "AVERAGE LOSS: 0.390529101273739\n",
      "MULTILABEL accuracy score: 0.2653558476881233\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9210250453309157, 0.7900257819582955, 0.9426988893925657, 0.8647084655485041, 0.9203521645512239, 0.8957034791477788, 0.5447146985494107]\n",
      "\n",
      "\n",
      "\n",
      "training time 419.44226336479187\n",
      "VALIDATION DATA STATS\n",
      "AVERAGE LOSS: 0.3574328773614505\n",
      "MULTILABEL accuracy score: 0.2918693832458731\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9310161677537233, 0.7944719454417982, 0.9515817204529521, 0.8679598036924515, 0.9219868703392892, 0.898170770570864, 0.6010112813104166]\n",
      "\n",
      "\n",
      "\n",
      "LOSS: 0.46021682024002075\n",
      "LOSS: 0.40659603476524353\n",
      "LOSS: 0.338273823261261\n",
      "LOSS: 0.3431890308856964\n",
      "LOSS: 0.3705896735191345\n",
      "LOSS: 0.38476455211639404\n",
      "LOSS: 0.35020917654037476\n",
      "LOSS: 0.358153373003006\n",
      "LOSS: 0.35525113344192505\n",
      "LOSS: 0.3948877453804016\n",
      "LOSS: 0.3700979948043823\n",
      "LOSS: 0.35655921697616577\n",
      "LOSS: 0.3918313682079315\n",
      "LOSS: 0.39446160197257996\n",
      "LOSS: 0.3582381308078766\n",
      "LOSS: 0.3751339316368103\n",
      "LOSS: 0.3687468469142914\n",
      "LOSS: 0.31019967794418335\n",
      "LOSS: 0.3383012115955353\n",
      "LOSS: 0.37893661856651306\n",
      "LOSS: 0.3560391962528229\n",
      "LOSS: 0.2975476384162903\n",
      "LOSS: 0.34361398220062256\n",
      "LOSS: 0.36986681818962097\n",
      "LOSS: 0.32408106327056885\n",
      "LOSS: 0.3422796130180359\n",
      "LOSS: 0.3223727345466614\n",
      "TRAINING DATA STATS\n",
      "AVERAGE LOSS: 0.36032693128583654\n",
      "MULTILABEL accuracy score: 0.29459428830462375\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9329244106980961, 0.7947855281051677, 0.9490523005439709, 0.8660754759746147, 0.9219033318223028, 0.8971413191296465, 0.5869928603807797]\n",
      "\n",
      "\n",
      "\n",
      "training time 350.7616081237793\n",
      "VALIDATION DATA STATS\n",
      "AVERAGE LOSS: 0.3173637635924894\n",
      "MULTILABEL accuracy score: 0.3388642206122926\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9520066285665725, 0.8008668125517857, 0.9572754891754658, 0.8678748220697274, 0.9234315579255986, 0.897150991098175, 0.6557394463447279]\n",
      "\n",
      "\n",
      "\n",
      "LOSS: 0.30392327904701233\n",
      "LOSS: 0.35277682542800903\n",
      "LOSS: 0.365085631608963\n",
      "LOSS: 0.3627585172653198\n",
      "LOSS: 0.32083192467689514\n",
      "LOSS: 0.3397945165634155\n",
      "LOSS: 0.3474937081336975\n",
      "LOSS: 0.41874951124191284\n",
      "LOSS: 0.3234066963195801\n",
      "LOSS: 0.3395349383354187\n",
      "LOSS: 0.2843673825263977\n",
      "LOSS: 0.2701984643936157\n",
      "LOSS: 0.3546953797340393\n",
      "LOSS: 0.3421097695827484\n",
      "LOSS: 0.3479316830635071\n",
      "LOSS: 0.33694037795066833\n",
      "LOSS: 0.31417936086654663\n",
      "LOSS: 0.3246956765651703\n",
      "LOSS: 0.30863067507743835\n",
      "LOSS: 0.3279043138027191\n",
      "LOSS: 0.33892783522605896\n",
      "LOSS: 0.26741823554039\n",
      "LOSS: 0.3152608871459961\n",
      "LOSS: 0.29912111163139343\n",
      "LOSS: 0.3213323652744293\n",
      "LOSS: 0.32977181673049927\n",
      "LOSS: 0.24737754464149475\n",
      "TRAINING DATA STATS\n",
      "AVERAGE LOSS: 0.32482599482575225\n",
      "MULTILABEL accuracy score: 0.3434383499546691\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9494276971894833, 0.7997435970081596, 0.9554765412511332, 0.8665712828649139, 0.924304453762466, 0.8989333068902992, 0.6478141999093382]\n",
      "\n",
      "\n",
      "\n",
      "training time 349.2460923194885\n",
      "VALIDATION DATA STATS\n",
      "AVERAGE LOSS: 0.25585675053298473\n",
      "MULTILABEL accuracy score: 0.449064139879751\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.976247636448618, 0.8324374853937836, 0.9737406785782574, 0.8678535766640464, 0.9260447428243642, 0.9113429220930974, 0.7752236078947927]\n",
      "\n",
      "\n",
      "\n",
      "LOSS: 0.2923128604888916\n",
      "LOSS: 0.28369390964508057\n",
      "LOSS: 0.29631268978118896\n",
      "LOSS: 0.25565004348754883\n",
      "LOSS: 0.26553285121917725\n",
      "LOSS: 0.2707683742046356\n",
      "LOSS: 0.2880803048610687\n",
      "LOSS: 0.28702640533447266\n",
      "LOSS: 0.300556480884552\n",
      "LOSS: 0.25532862544059753\n",
      "LOSS: 0.2789113521575928\n",
      "LOSS: 0.2799907326698303\n",
      "LOSS: 0.2622324228286743\n",
      "LOSS: 0.2644898295402527\n",
      "LOSS: 0.2782115638256073\n",
      "LOSS: 0.2876490354537964\n",
      "LOSS: 0.2681431770324707\n",
      "LOSS: 0.261780321598053\n",
      "LOSS: 0.2757110297679901\n",
      "LOSS: 0.29584628343582153\n",
      "LOSS: 0.2518790662288666\n",
      "LOSS: 0.24327266216278076\n",
      "LOSS: 0.305307537317276\n",
      "LOSS: 0.2808758616447449\n",
      "LOSS: 0.21259310841560364\n",
      "LOSS: 0.22611302137374878\n",
      "LOSS: 0.2982519567012787\n",
      "TRAINING DATA STATS\n",
      "AVERAGE LOSS: 0.27884836403732394\n",
      "MULTILABEL accuracy score: 0.41393500679963735\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9665967815049864, 0.815524422030825, 0.9630411378059837, 0.866925430643699, 0.9261176903898459, 0.9077161718041704, 0.7378810630099728]\n",
      "\n",
      "\n",
      "\n",
      "training time 350.8388946056366\n",
      "VALIDATION DATA STATS\n",
      "AVERAGE LOSS: 0.22216697531225887\n",
      "MULTILABEL accuracy score: 0.5244640846416962\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9826212581529244, 0.8540440629713825, 0.9777135694406085, 0.8680447853151756, 0.9256198347107438, 0.9292527990821985, 0.8586118251928021]\n",
      "\n",
      "\n",
      "\n",
      "LOSS: 0.2316090315580368\n",
      "LOSS: 0.2516070008277893\n",
      "LOSS: 0.27615323662757874\n",
      "LOSS: 0.23705358803272247\n",
      "LOSS: 0.23890137672424316\n",
      "LOSS: 0.2708697021007538\n",
      "LOSS: 0.3155505657196045\n",
      "LOSS: 0.2501320242881775\n",
      "LOSS: 0.23686566948890686\n",
      "LOSS: 0.2432355433702469\n",
      "LOSS: 0.2756693959236145\n",
      "LOSS: 0.26609155535697937\n",
      "LOSS: 0.2823737859725952\n",
      "LOSS: 0.2835037112236023\n",
      "LOSS: 0.2102706879377365\n",
      "LOSS: 0.25194138288497925\n",
      "LOSS: 0.22866345942020416\n",
      "LOSS: 0.23317091166973114\n",
      "LOSS: 0.2644898295402527\n",
      "LOSS: 0.2887366712093353\n",
      "LOSS: 0.22866103053092957\n",
      "LOSS: 0.2505224049091339\n",
      "LOSS: 0.26092278957366943\n",
      "LOSS: 0.22102658450603485\n",
      "LOSS: 0.23342794179916382\n",
      "LOSS: 0.2365727573633194\n",
      "LOSS: 0.2238379716873169\n",
      "TRAINING DATA STATS\n",
      "AVERAGE LOSS: 0.24823853782194913\n",
      "MULTILABEL accuracy score: 0.46322529465095197\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9740268019038985, 0.8309298504079783, 0.9685020965548504, 0.8671875, 0.929375849954669, 0.9206213168631007, 0.7872846781504986]\n",
      "\n",
      "\n",
      "\n",
      "training time 354.27632331848145\n",
      "VALIDATION DATA STATS\n",
      "AVERAGE LOSS: 0.199043492887817\n",
      "MULTILABEL accuracy score: 0.5604538018653467\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9879963457902229, 0.8728887378104485, 0.9817289511143216, 0.8680022945038135, 0.9166330281076717, 0.943699674945293, 0.8856572266247424]\n",
      "\n",
      "\n",
      "\n",
      "LOSS: 0.22091934084892273\n",
      "LOSS: 0.23909056186676025\n",
      "LOSS: 0.19814373552799225\n",
      "LOSS: 0.2481231689453125\n",
      "LOSS: 0.20475998520851135\n",
      "LOSS: 0.23158827424049377\n",
      "LOSS: 0.24297814071178436\n",
      "LOSS: 0.22288671135902405\n",
      "LOSS: 0.2637786567211151\n",
      "LOSS: 0.24408206343650818\n",
      "LOSS: 0.22314798831939697\n",
      "LOSS: 0.23375430703163147\n",
      "LOSS: 0.23191899061203003\n",
      "LOSS: 0.26220834255218506\n",
      "LOSS: 0.24575722217559814\n",
      "LOSS: 0.20050053298473358\n",
      "LOSS: 0.24056634306907654\n",
      "LOSS: 0.2504548728466034\n",
      "LOSS: 0.23249617218971252\n",
      "LOSS: 0.22898542881011963\n",
      "LOSS: 0.2015867978334427\n",
      "LOSS: 0.2182486355304718\n",
      "LOSS: 0.22050946950912476\n",
      "LOSS: 0.23024703562259674\n",
      "LOSS: 0.20563116669654846\n",
      "LOSS: 0.23655003309249878\n",
      "LOSS: 0.2220323234796524\n",
      "TRAINING DATA STATS\n",
      "AVERAGE LOSS: 0.23063675487787208\n",
      "MULTILABEL accuracy score: 0.4913871260199456\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9781419990933817, 0.8410513939256573, 0.9704994900271986, 0.8676549750679964, 0.9303957955575702, 0.9294820942883046, 0.8118837828649139]\n",
      "\n",
      "\n",
      "\n",
      "training time 352.2908890247345\n",
      "VALIDATION DATA STATS\n",
      "AVERAGE LOSS: 0.17933292105874937\n",
      "MULTILABEL accuracy score: 0.5790435318362405\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9912044020480572, 0.8785612611272813, 0.9836197922199325, 0.8663663982663748, 0.9299326520639911, 0.9502007690836857, 0.8874205952962672]\n",
      "\n",
      "\n",
      "\n",
      "LOSS: 0.2620595693588257\n",
      "LOSS: 0.2146916687488556\n",
      "LOSS: 0.2323799580335617\n",
      "LOSS: 0.25368234515190125\n",
      "LOSS: 0.19152230024337769\n",
      "LOSS: 0.2671152651309967\n",
      "LOSS: 0.23263637721538544\n",
      "LOSS: 0.19280961155891418\n",
      "LOSS: 0.18250030279159546\n",
      "LOSS: 0.20999257266521454\n",
      "LOSS: 0.23331111669540405\n",
      "LOSS: 0.20301669836044312\n",
      "LOSS: 0.19485622644424438\n",
      "LOSS: 0.2533104419708252\n",
      "LOSS: 0.23751157522201538\n",
      "LOSS: 0.18976165354251862\n",
      "LOSS: 0.19590945541858673\n",
      "LOSS: 0.19081194698810577\n",
      "LOSS: 0.22491207718849182\n",
      "LOSS: 0.2544653117656708\n",
      "LOSS: 0.25091010332107544\n",
      "LOSS: 0.21929006278514862\n",
      "LOSS: 0.21293488144874573\n",
      "LOSS: 0.2084222435951233\n",
      "LOSS: 0.24828454852104187\n",
      "LOSS: 0.2062043994665146\n",
      "LOSS: 0.18926076591014862\n",
      "TRAINING DATA STATS\n",
      "AVERAGE LOSS: 0.21966529074222094\n",
      "MULTILABEL accuracy score: 0.5083933023572076\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9811310063463282, 0.8481272665457842, 0.9737080689029919, 0.8676974728014506, 0.931854884406165, 0.9337460335448776, 0.8243214528558477]\n",
      "\n",
      "\n",
      "\n",
      "training time 350.7329556941986\n",
      "VALIDATION DATA STATS\n",
      "AVERAGE LOSS: 0.1727796513081083\n",
      "MULTILABEL accuracy score: 0.6008413180649684\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9925641080116425, 0.883192759565744, 0.9834285835688032, 0.8681085215322186, 0.9360938197114874, 0.9543223777858039, 0.9036308398308865]\n",
      "\n",
      "\n",
      "\n",
      "LOSS: 0.22049714624881744\n",
      "LOSS: 0.22200027108192444\n",
      "LOSS: 0.1746901422739029\n",
      "LOSS: 0.20784057676792145\n",
      "LOSS: 0.19807811081409454\n",
      "LOSS: 0.19733668863773346\n",
      "LOSS: 0.21352355182170868\n",
      "LOSS: 0.189124196767807\n",
      "LOSS: 0.2655585706233978\n",
      "LOSS: 0.22273612022399902\n",
      "LOSS: 0.19598446786403656\n",
      "LOSS: 0.19546255469322205\n",
      "LOSS: 0.21980854868888855\n",
      "LOSS: 0.2210765779018402\n",
      "LOSS: 0.20746582746505737\n",
      "LOSS: 0.19337913393974304\n",
      "LOSS: 0.18934625387191772\n",
      "LOSS: 0.26071709394454956\n",
      "LOSS: 0.21105995774269104\n",
      "LOSS: 0.1904674917459488\n",
      "LOSS: 0.18001340329647064\n",
      "LOSS: 0.2072826474905014\n",
      "LOSS: 0.21931962668895721\n",
      "LOSS: 0.1837538778781891\n",
      "LOSS: 0.21107050776481628\n",
      "LOSS: 0.18800286948680878\n",
      "LOSS: 0.20291894674301147\n",
      "TRAINING DATA STATS\n",
      "AVERAGE LOSS: 0.21093490766403575\n",
      "MULTILABEL accuracy score: 0.5246628513145966\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9825050997280145, 0.8530286718041704, 0.975322982774252, 0.8677541364460563, 0.9335122960108794, 0.9383074569356301, 0.8360508272892112]\n",
      "\n",
      "\n",
      "\n",
      "training time 353.4611847400665\n",
      "VALIDATION DATA STATS\n",
      "AVERAGE LOSS: 0.16278930041817544\n",
      "MULTILABEL accuracy score: 0.6135885614735813\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9939025685695468, 0.8888015466655336, 0.9826000127472434, 0.8680235399094945, 0.9374960164864348, 0.9579765875629395, 0.9105355966772185]\n",
      "\n",
      "\n",
      "\n",
      "LOSS: 0.20113489031791687\n",
      "LOSS: 0.24955375492572784\n",
      "LOSS: 0.24186059832572937\n",
      "LOSS: 0.24185070395469666\n",
      "LOSS: 0.1931343525648117\n",
      "LOSS: 0.18676474690437317\n",
      "LOSS: 0.2371513992547989\n",
      "LOSS: 0.24740390479564667\n",
      "LOSS: 0.1970026046037674\n",
      "LOSS: 0.26235440373420715\n",
      "LOSS: 0.22321030497550964\n",
      "LOSS: 0.2644977569580078\n",
      "LOSS: 0.22347857058048248\n",
      "LOSS: 0.18656550347805023\n",
      "LOSS: 0.23031923174858093\n",
      "LOSS: 0.24041326344013214\n",
      "LOSS: 0.17008820176124573\n",
      "LOSS: 0.20891231298446655\n",
      "LOSS: 0.2198994755744934\n",
      "LOSS: 0.1640247106552124\n",
      "LOSS: 0.22538478672504425\n",
      "LOSS: 0.2182619869709015\n",
      "LOSS: 0.17637141048908234\n",
      "LOSS: 0.22062841057777405\n",
      "LOSS: 0.21795383095741272\n",
      "LOSS: 0.1749129444360733\n",
      "LOSS: 0.24774055182933807\n",
      "TRAINING DATA STATS\n",
      "AVERAGE LOSS: 0.20511964843663322\n",
      "MULTILABEL accuracy score: 0.5337007026291931\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9837587828649139, 0.8565276518585675, 0.9762083522212148, 0.8680870353581143, 0.9346668177697189, 0.9407581595648232, 0.842439653218495]\n",
      "\n",
      "\n",
      "\n",
      "training time 350.27391839027405\n",
      "VALIDATION DATA STATS\n",
      "AVERAGE LOSS: 0.17300092679974827\n",
      "MULTILABEL accuracy score: 0.6126750090292974\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9938600777581847, 0.8888015466655336, 0.9857443327880346, 0.863498268499437, 0.9381121332511845, 0.9596124838003781, 0.9089846820625039]\n",
      "\n",
      "\n",
      "\n",
      "LOSS: 0.19738620519638062\n",
      "LOSS: 0.17274346947669983\n",
      "LOSS: 0.21764954924583435\n",
      "LOSS: 0.20516198873519897\n",
      "LOSS: 0.23407508432865143\n",
      "LOSS: 0.2117794007062912\n",
      "LOSS: 0.21219788491725922\n",
      "LOSS: 0.20435117185115814\n",
      "LOSS: 0.199252188205719\n",
      "LOSS: 0.20367971062660217\n",
      "LOSS: 0.23149096965789795\n",
      "LOSS: 0.21479015052318573\n",
      "LOSS: 0.19762173295021057\n",
      "LOSS: 0.23581306636333466\n",
      "LOSS: 0.18089541792869568\n",
      "LOSS: 0.18147560954093933\n",
      "LOSS: 0.21658293902873993\n",
      "LOSS: 0.20164594054222107\n",
      "LOSS: 0.1911771595478058\n",
      "LOSS: 0.17672832310199738\n",
      "LOSS: 0.17885778844356537\n",
      "LOSS: 0.20742546021938324\n",
      "LOSS: 0.2546771466732025\n",
      "LOSS: 0.16654500365257263\n",
      "LOSS: 0.23142722249031067\n",
      "LOSS: 0.18058699369430542\n",
      "LOSS: 0.19054488837718964\n",
      "TRAINING DATA STATS\n",
      "AVERAGE LOSS: 0.2006054066614681\n",
      "MULTILABEL accuracy score: 0.5426535584768812\n",
      "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
      "[0.9849912171350861, 0.8584967135086129, 0.9771858000906618, 0.8681436990027198, 0.9359417497733454, 0.9418843495013599, 0.8494730281051677]\n",
      "\n",
      "\n",
      "\n",
      "training time 352.976446390152\n"
     ]
    }
   ],
   "source": [
    "ct = 1\n",
    "for train_index, test_index in skf.split(df,df['unique_label']):\n",
    "    if ct!=1:\n",
    "        model.apply(reset_weights);\n",
    "    dataset_train = DatasetMultiLabel(df = df.loc[train_index])\n",
    "    dataset_val = DatasetMultiLabel(df = df.loc[test_index])\n",
    "    loader_train = create_loader(\n",
    "        dataset_train,\n",
    "        input_size=data_config[\"input_size\"],\n",
    "        batch_size=64,\n",
    "        is_training=True,\n",
    "        mean=data_config[\"mean\"],\n",
    "        std=data_config[\"std\"],\n",
    "       interpolation=data_config[\"interpolation\"],\n",
    "    )\n",
    "    loader_val = create_loader(\n",
    "        dataset_val,\n",
    "        input_size=data_config[\"input_size\"],\n",
    "        batch_size=64,\n",
    "        is_training=False,\n",
    "        mean=data_config[\"mean\"],\n",
    "        std=data_config[\"std\"],\n",
    "        interpolation=data_config[\"interpolation\"],\n",
    "\n",
    "    )\n",
    "    model.fit(loader_train,loader_val,num_epochs=40)\n",
    "    checkpoint = torch.load(\"weights_model/model_best.pth.tar\")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    pred_val = model.predict_proba(loader_val)\n",
    "    df_pred = create_df(pred_val,dataset_val)\n",
    "    df_pred.to_csv(str(ct)+\"_fold.csv\",index=False)\n",
    "    ct+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'os' from '/usr/lib/python3.8/os.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl = []\n",
    "for i in range(1,num_splits+1):\n",
    "    dfl.append(pd.read_csv(str(i)+\"_fold.csv\"))\n",
    "    \n",
    "\n",
    "cols = dfl[0].columns[1:]\n",
    "\n",
    "df_pred = pd.concat(dfl,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = df_pred[cols].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open('pred_probs.npy','wb'),pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(df_pred['image_loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pickle' from '/usr/lib/python3.8/pickle.py'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.dump(data,open(\"data.p\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
